<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Reflections – Research Methods and Professional Practice e-Portfolio</title>
  <link rel="stylesheet" href="style.css">
</head>

<body id="top">
  <div class="main-wrapper">

    <header class="site-header">
      <div class="brand">
        <h1>Research Methods and Professional Practice</h1>
        <span>MSc Artificial Intelligence – e-Portfolio</span>
      </div>

      <nav class="main-nav">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="discussion.html">Discussions</a></li>
          <li><a href="research.html">Research &amp; Proposal</a></li>
          <li><a href="statistics.html">Statistics &amp; Data</a></li>
          <li><a href="reflections.html" class="active">Reflections</a></li>
          <li><a href="activities.html">Activities</a></li>
          <li><a href="about.html">About</a></li>
        </ul>
      </nav>
    </header>

    <main class="page-grid">
      <section>

        <!-- Reflective Activity 1 -->
        <div class="card" id="ethics">
          <div class="card-header">
            <h2 class="page-title">Reflective Activity 1: Ethics in Computing</h2>
            <div class="meta small-muted">Unit 1 · Ethics in Computing in the Age of Generative AI</div>
          </div>

          <p><strong>Ethics in Computing in the Age of Generative AI</strong></p>

          <h4>What – Context and focus</h4>
          <p>
            Since late 2022, generative AI (GenAI) tools have moved from research labs into everyday life. They now write code,
            draft emails, summarise medical articles and generate realistic images. As Correa et al. (2023) show, this rapid
            adoption has triggered a wave of more than 200 AI ethics guidelines worldwide, but these documents differ in scope,
            terminology and legal force. Deckard (2023) adds that organisations face strong pressure to “move fast” with GenAI
            to gain competitive advantage, even when governance structures are still immature.
          </p>

          <p>
            For computing professionals, this raises a simple but difficult question: how can we use GenAI responsibly when
            global norms are fragmented and the technology is still evolving? In this reflection I draw on Correa et al.
            (2023), Deckard (2023), and professional codes such as ACM (2018) and BCS (2021, 2024) to develop my own view.
            I also connect the discussion to my background as a biomedical engineer and AI student who is particularly
            interested in healthcare and human physiology.
          </p>

          <h4>So what – Analysis and position</h4>

          <h5>1. Fragmented principles and the need for enforceable baselines</h5>
          <p>
            Correa et al. (2023) show that most AI ethics documents repeat similar high-level values – fairness, transparency,
            accountability, privacy, human oversight – but differ on how to implement or enforce them. Many guidelines are
            voluntary and lack mechanisms for monitoring or sanctions. I see a risk that GenAI becomes governed by “ethics
            washing”: beautiful principles with little impact on practice.
          </p>

          <p>
            A layered governance approach is needed. Global frameworks such as the OECD principles and the EU AI Act should
            define enforceable baselines for safety, transparency and data protection. Professional bodies like ACM and BCS
            should translate these into expectations for individual conduct. Organisations must then convert these principles
            into concrete policies, risk registers and technical controls.
          </p>

          <h5>2. Risk-tiered governance rather than one-size-fits-all rules</h5>
          <p>
            Not every GenAI system has the same potential for harm. A brainstorming tool is very different from a model that
            assists clinicians in prioritising critical patients. I support a risk-tiered model in which low-risk applications
            require lightweight safeguards, while high-risk uses demand strong oversight, formal testing, red-teaming and
            domain expert review.
          </p>

          <h5>3. Data governance, privacy and security</h5>
          <p>
            Many GenAI harms begin in the data pipeline. Training on scraped datasets raises legal and ethical concerns.
            In healthcare, misuse of patient information can directly violate confidentiality rules. Responsible GenAI requires
            strong data governance: clear legal bases for processing, data minimisation, security controls, DPIAs, and ensuring
            outputs cannot re-identify individuals.
          </p>

          <h5>4. Professional competence and honest use of GenAI</h5>
          <p>
            Competence today includes understanding GenAI limitations: hallucinations, bias, prompt vulnerabilities and misuse
            of training data. Transparency is essential—professionals must distinguish their own work from AI-assisted work and
            document where GenAI was used.
          </p>

          <h5>5. Human and physiological perspective</h5>
          <p>
            As a biomedical engineer, I recognise that physiological signals, medical notes and mental-health data are deeply
            personal. GenAI systems influencing medical decisions must be designed around human limits, cognitive load and
            emotional wellbeing. AI should support clinicians, not replace them.
          </p>

          <p><strong>My position:</strong> Generative AI must be governed through enforceable, risk-tiered frameworks that combine
            global regulation, professional codes, organisational controls and human-centred design.</p>

          <h4>Now what – Recommended course of action</h4>
          <ul>
            <li>Create clear GenAI policies and risk registers in organisations.</li>
            <li>Require red-teaming and impact assessments for medium/high-risk uses.</li>
            <li>Mandate transparency mechanisms such as model cards and logging.</li>
            <li>Strengthen professional training on AI risks, law and ethics.</li>
            <li>Include diverse users in the evaluation of GenAI systems.</li>
          </ul>

          <h4>Conclusion</h4>
          <p>
            This activity shifted my perspective from enthusiasm to responsibility. GenAI is powerful but fragile, and its
            risks are deeply human. As I move forward in AI and healthcare, I aim to translate ethical principles into practical
            decisions that protect patients, respect data and prioritise wellbeing.
          </p>

          <h4>References</h4>
          <ul>
            <li>ACM (2018). ACM Code of Ethics and Professional Conduct.</li>
            <li>BCS (2021). Code of Conduct.</li>
            <li>BCS (2024). Code of Conduct.</li>
            <li>Correa et al. (2023). Worldwide AI ethics: A review of 200 guidelines.</li>
            <li>Deckard (2023). Executive considerations for adopting GenAI responsibly.</li>
            <li>European Parliament and Council (2016). GDPR.</li>
          </ul>

          <p class="back-to-top"><a href="#top">↑ Back to top</a></p>
        </div>

        <!-- Reflective Activity 2 (Updated) -->
        <div class="card" id="activity2">
          <div class="card-header">
            <h2>Reflective Activity 2: Case Study – Inappropriate Use of Surveys</h2>
            <div class="meta small-muted">Unit 5 · Case study on Cambridge Analytica and survey misuse</div>
          </div>

          <p>
            In 2018, the Cambridge Analytica scandal showed how seemingly harmless Facebook “personality quizzes” and surveys
            harvested data from millions of users—and their friends—without meaningful consent. Although framed as entertainment,
            the survey responses and associated profile data were profiled, analysed and monetised for political micro-targeting.
            This demonstrates how surveys can be misused when the true purpose is hidden and participants are treated merely as
            data sources.
          </p>

          <p>
            Ethically, consent was not informed or freely given. Users lacked awareness of how their data would be combined,
            processed and shared. Socially, the manipulated political campaigns may have contributed to increased polarisation.
            Legally, the event raised major concerns about data protection, lawful basis for processing and cross-border data
            transfers. Professionally, it contradicts core ACM and BCS principles on privacy, honesty and avoiding harm.
          </p>

          <p>
            This case emphasises that surveys are not neutral tools. Every questionnaire carries ethical obligations: clarity of
            purpose, transparency, informed consent and respect for autonomy. For my AI-in-healthcare work, this reinforces
            that I must clearly explain why I am collecting data, minimise the amount collected and ensure participants understand
            how their responses will be analysed and protected. Good questionnaire design requires honesty and safeguarding
            participant wellbeing—not just technical correctness.
          </p>

          <p class="back-to-top"><a href="#top">↑ Back to top</a></p>
        </div>

        <!-- Final reflection placeholder -->
        <div class="card" id="final-reflection">
          <div class="card-header">
            <h2>Final 1,000-word Reflection (Unit 12)</h2>
            <div class="meta small-muted">Unit 12 · Reserved for the end-of-module reflection</div>
          </div>

          <p>
            At the end of the module, I will complete a comprehensive 1,000-word reflection summarising my development in ethics,
            research design, collaboration, statistics and professional practice.
          </p>

          <p class="back-to-top"><a href="#top">↑ Back to top</a></p>
        </div>

      </section>

      <aside class="sidebar">
        <div class="card">
          <div class="card-header"><h3>Quick navigation</h3></div>
          <ul class="clean">
            <li><a href="#ethics">Reflective Activity 1 – Ethics in Computing</a></li>
            <li><a href="#activity2">Reflective Activity 2 – Surveys</a></li>
            <li><a href="#final-reflection">Final Reflection (Unit 12)</a></li>
          </ul>
        </div>

        <div class="card">
          <div class="card-header"><h3>Reflective themes</h3></div>
          <ul class="clean">
            <li><span class="tag-pill">Ethics</span> Responsible AI practice</li>
            <li><span class="tag-pill">Methods</span> Research &amp; Data Collection</li>
            <li><span class="tag-pill">Growth</span> Professional development</li>
          </ul>
        </div>
      </aside>

    </main>

    <footer class="site-footer">
      Reflections · Research Methods and Professional Practice – e-Portfolio
    </footer>

  </div>
</body>
</html>

