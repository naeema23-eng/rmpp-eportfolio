<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Discussion – Codes of Ethics &amp; Professional Conduct</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    /* same base styles as index, slightly trimmed */
    :root {
      --bg: #f7f1e8;
      --bg-alt: #fffaf3;
      --card: #ffffff;
      --accent: #8a7060;
      --text-main: #2f2a26;
      --text-muted: #6d6259;
      --border-subtle: #e0d3c6;
      --link: #5b6ea6;
      --link-hover: #3e4f8c;
      --radius-lg: 18px;
      --radius-pill: 999px;
      --shadow-soft: 0 10px 25px rgba(0, 0, 0, 0.06);
    }
    *{box-sizing:border-box;margin:0;padding:0;}
    body{
      font-family:"Inter",system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",sans-serif;
      background:radial-gradient(circle at top left,#fdf6ec 0,#f4ece4 40%,#f2e7da 100%);
      color:var(--text-main);
      line-height:1.7;
    }
    header{
      background:linear-gradient(135deg,#30465b,#4e6783);
      color:#fff;
      padding:18px 20px;
      box-shadow:var(--shadow-soft);
    }
    header .inner{
      max-width:1080px;
      margin:0 auto;
    }
    header h1{
      font-size:1.5rem;
      margin-bottom:4px;
    }
    header .meta{
      font-size:0.9rem;
      opacity:0.9;
    }
    nav{
      margin-top:10px;
      display:flex;
      flex-wrap:wrap;
      gap:8px;
    }
    nav a{
      text-decoration:none;
      font-size:0.9rem;
      padding:6px 14px;
      border-radius:var(--radius-pill);
      border:1px solid rgba(255,255,255,.35);
      color:#fff;
      background:rgba(255,255,255,.06);
    }
    nav a:hover{
      background:rgba(255,255,255,.16);
    }
    .page{
      max-width:840px;
      margin:0 auto 64px;
      padding:28px 20px 64px;
    }
    h2{
      font-size:1.3rem;
      margin:8px 0 4px;
    }
    h3{
      font-size:1.1rem;
      margin:20px 0 6px;
    }
    .tagline{
      font-size:0.95rem;
      color:var(--text-muted);
      margin-bottom:18px;
    }
    .section-card{
      background:var(--card);
      border-radius:var(--radius-lg);
      padding:20px 22px;
      box-shadow:var(--shadow-soft);
      border:1px solid var(--border-subtle);
      margin-bottom:22px;
    }
    .subheading{
      text-transform:uppercase;
      font-size:0.8rem;
      letter-spacing:.08em;
      color:var(--accent);
      margin-bottom:2px;
      font-weight:600;
    }
    .refs{
      font-size:0.9rem;
      margin-top:10px;
    }
    .refs p{
      margin-bottom:4px;
    }
    strong.label{
      display:inline-block;
      font-size:0.8rem;
      text-transform:uppercase;
      letter-spacing:.08em;
      color:var(--accent);
      margin-bottom:3px;
    }
    ul{
      padding-left:20px;
    }
    li{margin-bottom:4px;}
    .back-note{
      font-size:0.83rem;
      color:var(--text-muted);
      margin-top:4px;
    }
    @media(max-width:640px){
      .page{padding:22px 14px 40px;}
      header h1{font-size:1.3rem;}
    }
  </style>
</head>
<body>
<header>
  <div class="inner">
    <h1>Discussion: Codes of Ethics &amp; Professional Conduct</h1>
    <div class="meta">
      Naeema Abdalla Ahmed Alnaqbi &nbsp;|&nbsp; Research Methods &amp; Professional Practice &mdash; Units 1&ndash;3
    </div>
    <nav>
      <a href="index.html">Home</a>
      <a href="discussion.html">Discussion (Units 1&ndash;3)</a>
      <a href="reflective-activity-1.html">Reflective Activity 1</a>
      <a href="stats.html">Statistics Artefacts</a>
      <a href="proposal-eval.html">Lit Review &amp; Proposal Evaluation</a>
      <a href="reflection.html">Final 1,000-word Reflection</a>
    </nav>
  </div>
</header>

<div class="page">
  <p class="tagline">
    This page collects my initial post, three peer responses, and a summary post for
    <em>Collaborative Discussion 1: Codes of Ethics and Professional Conduct</em>.
    The focus is the ACM case study &ldquo;Data Breach at a Medical Database&rdquo; and
    its professional, legal, social and ethical implications.
  </p>

  <!-- Initial post -->
  <section class="section-card">
    <div class="subheading">Initial post</div>
    <h2>ACM Case Study &mdash; Data Breach at a Medical Database</h2>

    <p>
      A hospital&rsquo;s database breach is not only a security failure but an ethical collapse with legal,
      social, and professional consequences&mdash;especially when downstream AI systems may learn from,
      or be audited against, compromised data. Under the ACM Code of Ethics (2018), the organisation and its
      computing professionals failed to avoid harm (1.2) and respect privacy (1.6) due to inadequate safeguards
      and delayed disclosure. Principle 2.5 also requires thorough evaluation of risks and impacts,
      including robust pre-breach assessment and transparent post-breach response.
    </p>

    <p>
      The BCS Code of Conduct (2021) similarly requires acting in the public interest and upholding privacy,
      security, and wellbeing (Clause 1a), while Clause 2 emphasises competence and integrity. Research shows
      that health-data breaches amplify social harms such as re-identification, stigma, or discriminatory
      decision-making (Shen and Ma, 2022). If leaked datasets are reused in AI training, they may embed structural
      bias or distort predictions (Mehrabi et&nbsp;al., 2021), contradicting ACM 1.4 (fairness) and BCS
      non-discrimination expectations.
    </p>

    <p>
      Legally, GDPR Articles 33&ndash;34 mandate timely breach notification to authorities and affected individuals.
      Violating these duties reflects weak professional governance. As Soomro, Shah and Ahmed (2020) argue,
      many breaches arise from organisational deficiencies&mdash;poor controls, weak accountability, and insufficient
      risk management&mdash;not technical errors alone.
    </p>

    <p>
      Following module guidance, this case demonstrates the chain:<br>
      <strong>Professional lapse &rarr; Legal breach &rarr; Social harm.</strong><br>
      In healthcare, this chain is intensified because trust is essential for safe digital health and ethical AI innovation.
    </p>

    <p>
      To align with ACM/BCS expectations, organisations should adopt:
    </p>
    <ul>
      <li>privacy-by-design and security-by-design approaches</li>
      <li>tested breach-response procedures</li>
      <li>independent audits and bias/impact assessments before AI reuse of clinical data</li>
      <li>transparent communication to rebuild public and patient trust.</li>
    </ul>

    <div class="refs">
      <strong class="label">References</strong>
      <p>ACM (2018) <em>ACM Code of Ethics and Professional Conduct.</em> Available at: https://www.acm.org/code-of-ethics (Accessed: 12 November 2025).</p>
      <p>BCS (2021) <em>Code of Conduct.</em> British Computer Society. Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 12 November 2025).</p>
      <p>Corrêa, N.K. et al. (2023) &lsquo;Worldwide AI ethics: A review of 200 guidelines&rsquo;, <em>Patterns</em>, 4(10), 100857.</p>
      <p>European Parliament and Council (2016) <em>General Data Protection Regulation (EU) 2016/679.</em> Available at: https://gdpr.eu/ (Accessed: 12 November 2025).</p>
      <p>Mehrabi, N. et al. (2021) &lsquo;A survey on bias and fairness in machine learning&rsquo;, <em>ACM Computing Surveys</em>, 54(6), pp. 1–35.</p>
      <p>Shen, N. and Ma, J. (2022) &lsquo;Ethical challenges in protecting health information in the digital era&rsquo;, <em>Journal of Medical Systems</em>, 46(3), pp. 1–12.</p>
      <p>Soomro, Z.A., Shah, M.H. and Ahmed, J. (2020) &lsquo;Information security management needs more holistic approaches&rsquo;, <em>International Journal of Information Management</em>, 51, 102056.</p>
    </div>
  </section>

  <!-- Peer response 1 -->
  <section class="section-card">
    <div class="subheading">Peer response 1</div>
    <h3>Reply to Nikolaos &mdash; Data Poisoning and Accountability by Design</h3>

    <p>
      Hi Nikolaos, excellent analysis. I strongly agree that preserving a corrupted model after evidence of targeted
      manipulation breaches ACM 1.2 (avoid harm) and BCS Public Interest responsibilities. What you describe reflects a
      classic case of data poisoning within a human-in-the-loop feedback loop. Beyond bias mitigation, professional
      competence (ACM 2.2; BCS Clause 2) requires engineering adversarial resilience&mdash;such as gated feedback channels,
      anomaly detection on label patterns, and rollback procedures when poisoning or drift is detected.
    </p>

    <p>
      Your transparency point can also be framed as accountability by design: documenting known limitations, publishing
      model cards or change logs, and enabling stakeholders (e.g., parents, schools, civil-society organisations) to contest
      errors. This aligns with the EU Trustworthy AI guidelines emphasising human oversight and traceability.
    </p>

    <p>
      Fairness also needs measurable thresholds. Monitoring false-positive rates across protected groups and enforcing
      go/no-go deployment criteria strengthens both ACM 1.4 and BCS expectations around non-discrimination. When thresholds
      fail, ethics and engineering teams should co-sign remediation steps before redeployment.
    </p>

    <p>
      A final question for you: should independent red-team audits be mandatory before content-moderation systems for minors
      are deployed&mdash;and should this be enforced by ACM/BCS disciplinary bodies or by statutory law?
    </p>

    <div class="refs">
      <strong class="label">References</strong>
      <p>ACM (2018) <em>ACM Code of Ethics and Professional Conduct.</em> Available at: https://www.acm.org/code-of-ethics (Accessed: 12 November 2025).</p>
      <p>BCS (2021) <em>Code of Conduct.</em> British Computer Society. Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 12 November 2025).</p>
      <p>European Commission High-Level Expert Group on AI (2019) <em>Ethics Guidelines for Trustworthy AI.</em> Brussels.</p>
      <p>Fjeld, J. et al. (2020) <em>Principled Artificial Intelligence.</em> Cambridge, MA: Berkman Klein Center.</p>
    </div>
  </section>

  <!-- Peer response 2 -->
  <section class="section-card">
    <div class="subheading">Peer response 2</div>
    <h3>Reply to Nelson &mdash; Accessibility as Governance</h3>

    <p>
      Hi Nelson, strong and clear analysis. You rightly show that releasing an inaccessible feature violates ACM principles
      1.1, 1.2, 1.3 and 1.4, as well as the BCS duty to act in the public interest and prevent discrimination. Your point
      regarding the Equality Act 2010 is crucial: accessibility is not optional, and neglecting it constitutes unlawful
      discrimination.
    </p>

    <p>
      To extend your argument, research shows that accessibility failures often arise from organisational governance gaps,
      not just scheduling pressures. El&nbsp;Morr et&nbsp;al. (2024) find that many developers lack accessibility training,
      meaning violations are not identified early. This reflects a structural ethical issue: failing to meet ACM 2.3 (respect
      rules) and BCS Clause 2 (competence) because teams simply do not have embedded accessibility practices.
    </p>

    <p>
      Furthermore, accessibility maturity research (Lazar, Goldstein and Taylor, 2017) shows that embedding accessibility
      from the start significantly reduces cost, risk, and harm, while improving innovation. This positions accessibility as
      a core ethical requirement, not a late technical fix.
    </p>

    <p>
      Your post effectively connects ethical, social, and legal consequences. Reinforcing accessibility as a governance
      requirement would protect users and strengthen professional integrity across the software lifecycle.
    </p>

    <div class="refs">
      <strong class="label">References</strong>
      <p>BCS (2023) <em>Code of Conduct.</em> British Computer Society. Available at: https://www.bcs.org/membership/become-a-member/code-of-conduct/ (Accessed: 12 November 2025).</p>
      <p>El Morr, C. et al. (2024) &lsquo;Exploring the intersection of AI and inclusive design for people with disabilities&rsquo;, <em>Studies in Health Technology and Informatics</em>, 316, pp. 556–559.</p>
      <p>Horton, S. (2025) <em>Accessibility in Software Development: Case Study.</em> ACM.</p>
      <p>Lazar, J., Goldstein, D.F. and Taylor, A. (2017) <em>Ensuring Digital Accessibility Through Process and Policy.</em> CRC Press.</p>
      <p>Shneiderman, B. (2020) <em>Designing the User Interface: Strategies for Effective Human–Computer Interaction.</em> 6th edn. Pearson.</p>
    </div>
  </section>

  <!-- Peer response 3 -->
  <section class="section-card">
    <div class="subheading">Peer response 3</div>
    <h3>Reply to Ali &mdash; Governance, AI Risk and GDPR</h3>

    <p>
      Hi Ali, your post provides a clear overview of the ethical duties breached in the <em>Data Breach at a Medical Database</em>
      case, especially around ACM Principles 1.2 (Avoid Harm) and 1.6 (Respect Privacy). I agree that delayed disclosure is
      not just a technical failure but a fundamental breach of professional accountability. I&rsquo;d like to build on your
      argument by expanding the connection between organisational governance, AI implications, and enforceable accountability.
    </p>

    <p>
      Recent research shows that in healthcare, breaches often occur not because organisations lack cybersecurity tools, but
      because they lack governance structures that enforce ethical decision-making and rapid incident response (Soomro, Shah
      and Ahmed, 2020). This reinforces your point that inactivity itself becomes unethical: when organisations delay breach
      reporting, they violate both ACM Principle 2.5 (thorough evaluations of computer systems and their impacts) and BCS
      Clause 1a (due regard for privacy, safety, and wellbeing).
    </p>

    <p>
      Your argument about downstream AI risks is particularly important. Compromised medical datasets&mdash;if later used for
      clinical prediction models&mdash;can embed bias, distort risk scoring, or result in unsafe automated decisions.
      Mehrabi et&nbsp;al. (2021) emphasise that AI systems trained on tainted or incomplete data can cause discriminatory
      or unsafe outcomes, which directly contradicts ACM 1.4 (fairness) and BCS expectations around non-discrimination.
    </p>

    <p>
      I would also add that GDPR&rsquo;s 72-hour notification rule (Article 33) is not only a legal obligation but also an
      ethical safeguard designed to minimise harm. When organisations fail to report promptly, individuals lose the
      opportunity to protect themselves&mdash;for example by changing passwords, monitoring financial accounts, or alerting
      healthcare providers.
    </p>

    <p>
      One question for you: given the rising frequency of healthcare breaches, do you think mandatory independent
      cybersecurity audits should be required for all organisations handling clinical data, and should failure to comply
      trigger BCS/ACM disciplinary action?
    </p>

    <div class="refs">
      <strong class="label">References</strong>
      <p>BCS (2024) <em>BCS Code of Conduct.</em> British Computer Society. Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 12 November 2025).</p>
      <p>European Parliament and Council (2016) <em>General Data Protection Regulation (EU 2016/679).</em> Available at: https://gdpr.eu/ (Accessed: 12 November 2025).</p>
      <p>Mehrabi, N. et al. (2021) &lsquo;A survey on bias and fairness in machine learning&rsquo;, <em>ACM Computing Surveys</em>, 54(6), pp. 1–35.</p>
      <p>Soomro, Z.A., Shah, M.H. and Ahmed, J. (2020) &lsquo;Information security management needs more holistic approaches: a review&rsquo;, <em>International Journal of Information Management</em>, 51, 102056.</p>
    </div>
  </section>

  <!-- Summary post -->
  <section class="section-card">
    <div class="subheading">Summary post</div>
    <h3>Summary &mdash; Codes of Ethics and Professional Conduct (Units 1&ndash;3)</h3>

    <p>
      Over the three-unit discussion, our exploration of professional, legal, social, and ethical responsibilities in
      computing revealed a central theme: the gap between ethical intention and enforceable accountability. Using the ACM
      and BCS Codes of Conduct as ethical anchors, we examined how computing professionalism extends beyond compliance to
      moral stewardship&mdash;particularly in sensitive areas such as healthcare AI, data protection, and inclusive design.
    </p>

    <p>
      In my initial post on the ACM Case Study <em>Data Breach at a Medical Database</em>, I analysed how failure to disclose
      patient-data breaches violates ACM Principles 1.2 (avoid harm) and 1.6 (respect privacy), as well as GDPR Articles
      33–34. The case demonstrated that ethical negligence in digital-health systems can quickly escalate into legal and
      social harm, eroding public trust.
    </p>

    <p>
      In peer responses, I engaged with cases such as Blocker Plus, Accessibility in Software Development, and Data Breach
      Ethics, which echoed similar concerns. Nikolaos&rsquo;s analysis of algorithmic bias underscored that ethics must move
      beyond bias mitigation toward adversarial resilience and accountability by design. Nelson&rsquo;s case highlighted that
      overlooking accessibility constitutes both a professional and moral failure. Ali&rsquo;s case reinforced the necessity
      of combining technical innovation with ethical governance and transparent reporting.
    </p>

    <p>
      Across all discussions, three insights emerged:
    </p>
    <ul>
      <li><strong>Professional:</strong> Ethical competence requires proactive governance, transparency, and continuous auditing.</li>
      <li><strong>Legal:</strong> Frameworks such as GDPR and the Equality Act 2010 convert ethical duties into enforceable obligations.</li>
      <li><strong>Social:</strong> Inclusive and privacy-preserving systems protect fairness, dignity, and public trust.</li>
    </ul>

    <p>
      Ultimately, the discussion affirmed that ethical codes alone are insufficient without institutional accountability.
      Computing professionals must act as both innovators and moral stewards&mdash;ensuring technology advances human
      well-being, equity, and justice.
    </p>

    <div class="refs">
      <strong class="label">References</strong>
      <p>ACM (2018) <em>ACM Code of Ethics and Professional Conduct.</em> Available at: https://www.acm.org/code-of-ethics (Accessed: 12 November 2025).</p>
      <p>BCS (2021) <em>Code of Conduct.</em> British Computer Society. Available at: https://www.bcs.org/membership/become-a-member/bcs-code-of-conduct/ (Accessed: 12 November 2025).</p>
      <p>Corrêa, N.K. et al. (2023) &lsquo;Worldwide AI ethics: A review of 200 guidelines&rsquo;, <em>Patterns</em>, 4(10), 100857.</p>
      <p>Fjeld, J. et al. (2020) <em>Principled Artificial Intelligence.</em> Cambridge, MA: Berkman Klein Center.</p>
      <p>Lazar, J., Goldstein, D.F. and Taylor, A. (2017) <em>Ensuring Digital Accessibility Through Process and Policy.</em> Boca Raton: CRC Press.</p>
      <p>Mehrabi, N. et al. (2021) &lsquo;A survey on bias and fairness in machine learning&rsquo;, <em>ACM Computing Surveys</em>, 54(6), pp. 1–35.</p>
      <p>Shen, N. and Ma, J. (2022) &lsquo;Ethical challenges in protecting health information in the digital era&rsquo;, <em>Journal of Medical Systems</em>, 46(3), pp. 1–12.</p>
      <p>Soomro, Z.A., Shah, M.H. and Ahmed, J. (2020) &lsquo;Information security management needs more holistic approaches: a review&rsquo;, <em>International Journal of Information Management</em>, 51, 102056.</p>
    </div>
  </section>

  <p class="back-note">
    Back to <a href="index.html">Home</a>.
  </p>
</div>
</body>
</html>
